{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import *\n",
    "from lasso_small import lasso\n",
    "from lasso_small import max_lamb\n",
    "from lasso_small import RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimension\n",
    "d = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load data\n",
    "# load train data\n",
    "# num of training data\n",
    "n = 10000\n",
    "train_data = np.loadtxt('./data/trainData.txt')\n",
    "train_data = coo_matrix((train_data[:,2],(train_data[:,1]-1,train_data[:,0]-1)),shape=(d,n)).tocsr()\n",
    "train_labels = np.loadtxt('./data/trainLabels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod validation data\n",
    "val_data = np.loadtxt('./data/valData.txt')\n",
    "val_data = coo_matrix((val_data[:,2],(val_data[:,1]-1,val_data[:,0]-1)),shape=(d,n)).tocsr()\n",
    "val_labels = np.loadtxt('./data/valLabels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model\n",
    "lamb = max_lamb(train_data,train_labels)\n",
    "l_wine = lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_val_loss = 100\n",
    "train_loss = np.inf\n",
    "train_loss_list = []\n",
    "val_loss = np.inf\n",
    "val_loss_list = []\n",
    "nonzero_list = []\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_iterations:0 :inf \n",
      "train_iterations:1 :77349310.075875 \n",
      "train_iterations:2 :654.434676 \n",
      "train_iterations:3 :66.610487 \n",
      "train_iterations:4 :37.463760 \n",
      "train_iterations:5 :15.522515 \n",
      "train_iterations:6 :6.461641 \n",
      "train_iterations:7 :2.822045 \n",
      "train_iterations:8 :1.246996 \n",
      "train_iterations:9 :0.547696 \n",
      "train_iterations:10 :0.238921 \n",
      "train_iterations:11 :0.103866 \n",
      "train_iterations:12 :0.045112 \n",
      "train_iterations:13 :0.019596 \n",
      "train_iterations:14 :0.008516 \n",
      "train_iterations:15 :0.003702 \n",
      "train_iterations:16 :0.001609 \n",
      "train_iterations:17 :0.000700 \n",
      "epoch1:train_loss,9.647635 val_loss:9.703867 lamb: 224.159533\n",
      "train_iterations:0 :inf \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\environment\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:742: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_iterations:1 :3827.783185 \n",
      "train_iterations:2 :223.624545 \n",
      "train_iterations:3 :20.474809 \n",
      "train_iterations:4 :17.307234 \n",
      "train_iterations:5 :10.490830 \n",
      "train_iterations:6 :5.239375 \n",
      "train_iterations:7 :2.427803 \n",
      "train_iterations:8 :1.104685 \n",
      "train_iterations:9 :0.505858 \n",
      "train_iterations:10 :0.234508 \n",
      "train_iterations:11 :0.109783 \n",
      "train_iterations:12 :0.051678 \n",
      "train_iterations:13 :0.024382 \n",
      "train_iterations:14 :0.011683 \n",
      "train_iterations:15 :0.005604 \n",
      "train_iterations:16 :0.002666 \n",
      "train_iterations:17 :0.001262 \n",
      "train_iterations:18 :0.000597 \n",
      "epoch2:train_loss,8.195161 val_loss:8.326086 lamb: 112.079767\n",
      "train_iterations:0 :inf \n",
      "train_iterations:1 :3124.267032 \n",
      "train_iterations:2 :369.583973 \n",
      "train_iterations:3 :40.634985 \n",
      "train_iterations:4 :28.078925 \n",
      "train_iterations:5 :22.585963 \n",
      "train_iterations:6 :18.177598 \n",
      "train_iterations:7 :13.981637 \n",
      "train_iterations:8 :10.022305 \n",
      "train_iterations:9 :6.671670 \n",
      "train_iterations:10 :4.197850 \n",
      "train_iterations:11 :2.829068 \n",
      "train_iterations:12 :2.002542 \n",
      "train_iterations:13 :1.331212 \n",
      "train_iterations:14 :0.848292 \n",
      "train_iterations:15 :0.530119 \n",
      "train_iterations:16 :0.329836 \n",
      "train_iterations:17 :0.205990 \n",
      "train_iterations:18 :0.129515 \n",
      "train_iterations:19 :0.081966 \n",
      "train_iterations:20 :0.052124 \n",
      "train_iterations:21 :0.033239 \n",
      "train_iterations:22 :0.021220 \n",
      "train_iterations:23 :0.013592 \n",
      "train_iterations:24 :0.008650 \n",
      "train_iterations:25 :0.005469 \n",
      "train_iterations:26 :0.003446 \n",
      "train_iterations:27 :0.002158 \n",
      "train_iterations:28 :0.001341 \n",
      "train_iterations:29 :0.000826 \n",
      "train_iterations:30 :0.000506 \n",
      "epoch3:train_loss,6.817563 val_loss:7.048168 lamb: 56.039883\n",
      "train_iterations:0 :inf \n",
      "train_iterations:1 :2864.265576 \n",
      "train_iterations:2 :403.645473 \n",
      "train_iterations:3 :38.810139 \n",
      "train_iterations:4 :24.121464 \n",
      "train_iterations:5 :20.602439 \n",
      "train_iterations:6 :19.158042 \n",
      "train_iterations:7 :18.061471 \n",
      "train_iterations:8 :17.197378 \n",
      "train_iterations:9 :16.160118 \n",
      "train_iterations:10 :14.632330 \n",
      "train_iterations:11 :12.598306 \n",
      "train_iterations:12 :10.303904 \n",
      "train_iterations:13 :8.062853 \n",
      "train_iterations:14 :6.199120 \n",
      "train_iterations:15 :4.694386 \n",
      "train_iterations:16 :3.522241 \n",
      "train_iterations:17 :2.633131 \n",
      "train_iterations:18 :1.967874 \n",
      "train_iterations:19 :1.473689 \n",
      "train_iterations:20 :1.115735 \n",
      "train_iterations:21 :0.855113 \n",
      "train_iterations:22 :0.661601 \n",
      "train_iterations:23 :0.516131 \n",
      "train_iterations:24 :0.404749 \n",
      "train_iterations:25 :0.318154 \n",
      "train_iterations:26 :0.250230 \n",
      "train_iterations:27 :0.196740 \n",
      "train_iterations:28 :0.154567 \n",
      "train_iterations:29 :0.121321 \n",
      "train_iterations:30 :0.095131 \n",
      "train_iterations:31 :0.074525 \n",
      "train_iterations:32 :0.058335 \n",
      "train_iterations:33 :0.045634 \n",
      "train_iterations:34 :0.035684 \n",
      "train_iterations:35 :0.027898 \n",
      "train_iterations:36 :0.021810 \n",
      "train_iterations:37 :0.017052 \n",
      "train_iterations:38 :0.013333 \n",
      "train_iterations:39 :0.010421 \n",
      "train_iterations:40 :0.008170 \n",
      "train_iterations:41 :0.006418 \n",
      "train_iterations:42 :0.005043 \n",
      "train_iterations:43 :0.003960 \n",
      "train_iterations:44 :0.003107 \n",
      "train_iterations:45 :0.002437 \n",
      "train_iterations:46 :0.001910 \n",
      "train_iterations:47 :0.001497 \n",
      "train_iterations:48 :0.001173 \n",
      "train_iterations:49 :0.000920 \n",
      "train_iterations:50 :0.000721 \n",
      "train_iterations:51 :0.000565 \n",
      "epoch4:train_loss,5.606264 val_loss:5.926701 lamb: 28.019942\n",
      "train_iterations:0 :inf \n",
      "train_iterations:1 :2022.403227 \n",
      "train_iterations:2 :305.890147 \n",
      "train_iterations:3 :34.748101 \n",
      "train_iterations:4 :22.374258 \n",
      "train_iterations:5 :20.818023 \n",
      "train_iterations:6 :19.858486 \n",
      "train_iterations:7 :18.800268 \n",
      "train_iterations:8 :17.667061 \n",
      "train_iterations:9 :16.607840 \n",
      "train_iterations:10 :15.615611 \n",
      "train_iterations:11 :14.584064 \n",
      "train_iterations:12 :13.449154 \n",
      "train_iterations:13 :12.030598 \n",
      "train_iterations:14 :10.388796 \n",
      "train_iterations:15 :8.825205 \n",
      "train_iterations:16 :7.419344 \n",
      "train_iterations:17 :6.203208 \n",
      "train_iterations:18 :5.181577 \n",
      "train_iterations:19 :4.330931 \n",
      "train_iterations:20 :3.628921 \n",
      "train_iterations:21 :3.052751 \n",
      "train_iterations:22 :2.580845 \n",
      "train_iterations:23 :2.193527 \n",
      "train_iterations:24 :1.873733 \n",
      "train_iterations:25 :1.606319 \n",
      "train_iterations:26 :1.380712 \n",
      "train_iterations:27 :1.189365 \n",
      "train_iterations:28 :1.026499 \n",
      "train_iterations:29 :0.886528 \n",
      "train_iterations:30 :0.765197 \n",
      "train_iterations:31 :0.658486 \n",
      "train_iterations:32 :0.565144 \n",
      "train_iterations:33 :0.481504 \n",
      "train_iterations:34 :0.407740 \n",
      "train_iterations:35 :0.347160 \n",
      "train_iterations:36 :0.296389 \n",
      "train_iterations:37 :0.253776 \n",
      "train_iterations:38 :0.217752 \n",
      "train_iterations:39 :0.186949 \n",
      "train_iterations:40 :0.160425 \n",
      "train_iterations:41 :0.137534 \n",
      "train_iterations:42 :0.117787 \n",
      "train_iterations:43 :0.100782 \n",
      "train_iterations:44 :0.086168 \n",
      "train_iterations:45 :0.073644 \n",
      "train_iterations:46 :0.062935 \n",
      "train_iterations:47 :0.053797 \n",
      "train_iterations:48 :0.046009 \n",
      "train_iterations:49 :0.039374 \n",
      "train_iterations:50 :0.033720 \n",
      "train_iterations:51 :0.028900 \n",
      "train_iterations:52 :0.024787 \n",
      "train_iterations:53 :0.021272 \n",
      "train_iterations:54 :0.018265 \n",
      "train_iterations:55 :0.015688 \n",
      "train_iterations:56 :0.013480 \n",
      "train_iterations:57 :0.011585 \n",
      "train_iterations:58 :0.009958 \n",
      "train_iterations:59 :0.008561 \n",
      "train_iterations:60 :0.007361 \n",
      "train_iterations:61 :0.006330 \n",
      "train_iterations:62 :0.005444 \n",
      "train_iterations:63 :0.004683 \n",
      "train_iterations:64 :0.004028 \n",
      "train_iterations:65 :0.003467 \n",
      "train_iterations:66 :0.002984 \n",
      "train_iterations:67 :0.002569 \n",
      "train_iterations:68 :0.002213 \n",
      "train_iterations:69 :0.001907 \n",
      "train_iterations:70 :0.001644 \n",
      "train_iterations:71 :0.001419 \n",
      "train_iterations:72 :0.001225 \n",
      "train_iterations:73 :0.001058 \n",
      "train_iterations:74 :0.000915 \n",
      "train_iterations:75 :0.000792 \n",
      "train_iterations:76 :0.000686 \n",
      "train_iterations:77 :0.000596 \n",
      "train_iterations:78 :0.000517 \n",
      "epoch5:train_loss,4.707292 val_loss:5.107541 lamb: 14.009971\n",
      "train_iterations:0 :inf \n",
      "train_iterations:1 :1857.066798 \n",
      "train_iterations:2 :257.653563 \n",
      "train_iterations:3 :32.243995 \n",
      "train_iterations:4 :17.483680 \n",
      "train_iterations:5 :14.720123 \n",
      "train_iterations:6 :13.552654 \n",
      "train_iterations:7 :12.678127 \n",
      "train_iterations:8 :11.937861 \n",
      "train_iterations:9 :11.323797 \n",
      "train_iterations:10 :10.835555 \n",
      "train_iterations:11 :10.429379 \n",
      "train_iterations:12 :10.066056 \n",
      "train_iterations:13 :9.675996 \n",
      "train_iterations:14 :9.192310 \n",
      "train_iterations:15 :8.567254 \n",
      "train_iterations:16 :7.893561 \n",
      "train_iterations:17 :7.171049 \n",
      "train_iterations:18 :6.418825 \n",
      "train_iterations:19 :5.703033 \n",
      "train_iterations:20 :5.050706 \n",
      "train_iterations:21 :4.447970 \n",
      "train_iterations:22 :3.901377 \n",
      "train_iterations:23 :3.410228 \n",
      "train_iterations:24 :2.999580 \n",
      "train_iterations:25 :2.664437 \n",
      "train_iterations:26 :2.385254 \n",
      "train_iterations:27 :2.144674 \n",
      "train_iterations:28 :1.932597 \n",
      "train_iterations:29 :1.743396 \n",
      "train_iterations:30 :1.573683 \n",
      "train_iterations:31 :1.420857 \n",
      "train_iterations:32 :1.284032 \n",
      "train_iterations:33 :1.160562 \n",
      "train_iterations:34 :1.048166 \n",
      "train_iterations:35 :0.945925 \n",
      "train_iterations:36 :0.853016 \n",
      "train_iterations:37 :0.768659 \n",
      "train_iterations:38 :0.692149 \n",
      "train_iterations:39 :0.622865 \n",
      "train_iterations:40 :0.560235 \n",
      "train_iterations:41 :0.503725 \n",
      "train_iterations:42 :0.452824 \n",
      "train_iterations:43 :0.407089 \n",
      "train_iterations:44 :0.365845 \n",
      "train_iterations:45 :0.329362 \n",
      "train_iterations:46 :0.296845 \n",
      "train_iterations:47 :0.267767 \n",
      "train_iterations:48 :0.241640 \n",
      "train_iterations:49 :0.218074 \n",
      "train_iterations:50 :0.196780 \n",
      "train_iterations:51 :0.177551 \n",
      "train_iterations:52 :0.160199 \n",
      "train_iterations:53 :0.144544 \n",
      "train_iterations:54 :0.130391 \n",
      "train_iterations:55 :0.117628 \n",
      "train_iterations:56 :0.106117 \n",
      "train_iterations:57 :0.095730 \n",
      "train_iterations:58 :0.086357 \n",
      "train_iterations:59 :0.077901 \n",
      "train_iterations:60 :0.070277 \n",
      "train_iterations:61 :0.063405 \n",
      "train_iterations:62 :0.057215 \n",
      "train_iterations:63 :0.051641 \n",
      "train_iterations:64 :0.046622 \n",
      "train_iterations:65 :0.042103 \n",
      "train_iterations:66 :0.038034 \n",
      "train_iterations:67 :0.034371 \n",
      "train_iterations:68 :0.031072 \n",
      "train_iterations:69 :0.028101 \n",
      "train_iterations:70 :0.025424 \n",
      "train_iterations:71 :0.023011 \n",
      "train_iterations:72 :0.020837 \n",
      "train_iterations:73 :0.018876 \n",
      "train_iterations:74 :0.017107 \n",
      "train_iterations:75 :0.015512 \n",
      "train_iterations:76 :0.014072 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_iterations:77 :0.012771 \n",
      "train_iterations:78 :0.011597 \n",
      "train_iterations:79 :0.010536 \n",
      "train_iterations:80 :0.009576 \n",
      "train_iterations:81 :0.008709 \n",
      "train_iterations:82 :0.007924 \n",
      "train_iterations:83 :0.007214 \n",
      "train_iterations:84 :0.006571 \n",
      "train_iterations:85 :0.005989 \n",
      "train_iterations:86 :0.005462 \n",
      "train_iterations:87 :0.004983 \n",
      "train_iterations:88 :0.004550 \n",
      "train_iterations:89 :0.004156 \n",
      "train_iterations:90 :0.003799 \n",
      "train_iterations:91 :0.003475 \n",
      "train_iterations:92 :0.003180 \n",
      "train_iterations:93 :0.002912 \n",
      "train_iterations:94 :0.002669 \n",
      "train_iterations:95 :0.002447 \n",
      "train_iterations:96 :0.002245 \n",
      "train_iterations:97 :0.002061 \n",
      "train_iterations:98 :0.001894 \n",
      "train_iterations:99 :0.001741 \n",
      "train_iterations:100 :0.001602 \n",
      "train_iterations:101 :0.001475 \n",
      "train_iterations:102 :0.001358 \n",
      "train_iterations:103 :0.001252 \n",
      "train_iterations:104 :0.001155 \n",
      "train_iterations:105 :0.001066 \n",
      "train_iterations:106 :0.000985 \n",
      "train_iterations:107 :0.000911 \n",
      "train_iterations:108 :0.000843 \n",
      "train_iterations:109 :0.000780 \n",
      "train_iterations:110 :0.000723 \n",
      "train_iterations:111 :0.000670 \n",
      "train_iterations:112 :0.000622 \n",
      "train_iterations:113 :0.000577 \n",
      "train_iterations:114 :0.000536 \n",
      "epoch6:train_loss,3.865499 val_loss:4.443735 lamb: 7.004985\n",
      "train_iterations:0 :inf \n",
      "train_iterations:1 :1586.624886 \n",
      "train_iterations:2 :206.730643 \n",
      "train_iterations:3 :28.719502 \n",
      "train_iterations:4 :13.257474 \n",
      "train_iterations:5 :10.174300 \n",
      "train_iterations:6 :9.215677 \n",
      "train_iterations:7 :8.837707 \n",
      "train_iterations:8 :8.563176 \n",
      "train_iterations:9 :8.360083 \n",
      "train_iterations:10 :8.179548 \n",
      "train_iterations:11 :8.043767 \n",
      "train_iterations:12 :7.908611 \n",
      "train_iterations:13 :7.768829 \n",
      "train_iterations:14 :7.635021 \n",
      "train_iterations:15 :7.469393 \n",
      "train_iterations:16 :7.257731 \n",
      "train_iterations:17 :7.001595 \n",
      "train_iterations:18 :6.692679 \n",
      "train_iterations:19 :6.348405 \n",
      "train_iterations:20 :5.960726 \n",
      "train_iterations:21 :5.586399 \n",
      "train_iterations:22 :5.183926 \n",
      "train_iterations:23 :4.783496 \n",
      "train_iterations:24 :4.394304 \n",
      "train_iterations:25 :4.014197 \n",
      "train_iterations:26 :3.657424 \n",
      "train_iterations:27 :3.327880 \n",
      "train_iterations:28 :3.028227 \n",
      "train_iterations:29 :2.758067 \n",
      "train_iterations:30 :2.515731 \n",
      "train_iterations:31 :2.300224 \n",
      "train_iterations:32 :2.108149 \n",
      "train_iterations:33 :1.937954 \n",
      "train_iterations:34 :1.783517 \n",
      "train_iterations:35 :1.637867 \n",
      "train_iterations:36 :1.514111 \n",
      "train_iterations:37 :1.401196 \n",
      "train_iterations:38 :1.297798 \n",
      "train_iterations:39 :1.202581 \n",
      "train_iterations:40 :1.114441 \n",
      "train_iterations:41 :1.032931 \n",
      "train_iterations:42 :0.957202 \n",
      "train_iterations:43 :0.886661 \n",
      "train_iterations:44 :0.822024 \n",
      "train_iterations:45 :0.762235 \n",
      "train_iterations:46 :0.706792 \n",
      "train_iterations:47 :0.655195 \n",
      "train_iterations:48 :0.607039 \n",
      "train_iterations:49 :0.562169 \n",
      "train_iterations:50 :0.520381 \n",
      "train_iterations:51 :0.481480 \n",
      "train_iterations:52 :0.445571 \n",
      "train_iterations:53 :0.412223 \n",
      "train_iterations:54 :0.381265 \n",
      "train_iterations:55 :0.352574 \n",
      "train_iterations:56 :0.326028 \n",
      "train_iterations:57 :0.301500 \n",
      "train_iterations:58 :0.278858 \n",
      "train_iterations:59 :0.257971 \n",
      "train_iterations:60 :0.238744 \n",
      "train_iterations:61 :0.220997 \n",
      "train_iterations:62 :0.204704 \n",
      "train_iterations:63 :0.189677 \n",
      "train_iterations:64 :0.175796 \n",
      "train_iterations:65 :0.162967 \n",
      "train_iterations:66 :0.151086 \n",
      "train_iterations:67 :0.140091 \n",
      "train_iterations:68 :0.129959 \n",
      "train_iterations:69 :0.120537 \n",
      "train_iterations:70 :0.111789 \n",
      "train_iterations:71 :0.103665 \n",
      "train_iterations:72 :0.096124 \n",
      "train_iterations:73 :0.089124 \n",
      "train_iterations:74 :0.082634 \n",
      "train_iterations:75 :0.076616 \n",
      "train_iterations:76 :0.071037 \n",
      "train_iterations:77 :0.065865 \n",
      "train_iterations:78 :0.061069 \n",
      "train_iterations:79 :0.056623 \n",
      "train_iterations:80 :0.052501 \n",
      "train_iterations:81 :0.048681 \n",
      "train_iterations:82 :0.045137 \n",
      "train_iterations:83 :0.041849 \n",
      "train_iterations:84 :0.038801 \n",
      "train_iterations:85 :0.035975 \n",
      "train_iterations:86 :0.033355 \n",
      "train_iterations:87 :0.030927 \n",
      "train_iterations:88 :0.028678 \n",
      "train_iterations:89 :0.026594 \n",
      "train_iterations:90 :0.024664 \n",
      "train_iterations:91 :0.022876 \n",
      "train_iterations:92 :0.021221 \n",
      "train_iterations:93 :0.019689 \n",
      "train_iterations:94 :0.018270 \n",
      "train_iterations:95 :0.016956 \n",
      "train_iterations:96 :0.015740 \n",
      "train_iterations:97 :0.014614 \n",
      "train_iterations:98 :0.013574 \n",
      "train_iterations:99 :0.012610 \n",
      "train_iterations:100 :0.011718 \n",
      "train_iterations:101 :0.010889 \n",
      "train_iterations:102 :0.010120 \n",
      "train_iterations:103 :0.009410 \n",
      "train_iterations:104 :0.008751 \n",
      "train_iterations:105 :0.008139 \n",
      "train_iterations:106 :0.007571 \n",
      "train_iterations:107 :0.007042 \n",
      "train_iterations:108 :0.006550 \n",
      "train_iterations:109 :0.006092 \n",
      "train_iterations:110 :0.005667 \n",
      "train_iterations:111 :0.005272 \n",
      "train_iterations:112 :0.004905 \n",
      "train_iterations:113 :0.004566 \n",
      "train_iterations:114 :0.004251 \n",
      "train_iterations:115 :0.003960 \n",
      "train_iterations:116 :0.003690 \n",
      "train_iterations:117 :0.003205 \n",
      "train_iterations:118 :0.002637 \n",
      "train_iterations:119 :0.002339 \n",
      "train_iterations:120 :0.002106 \n",
      "train_iterations:121 :0.001913 \n",
      "train_iterations:122 :0.001742 \n",
      "train_iterations:123 :0.001588 \n",
      "train_iterations:124 :0.001450 \n",
      "train_iterations:125 :0.001325 \n",
      "train_iterations:126 :0.001215 \n",
      "train_iterations:127 :0.001117 \n",
      "train_iterations:128 :0.001030 \n",
      "train_iterations:129 :0.000952 \n",
      "train_iterations:130 :0.000881 \n",
      "train_iterations:131 :0.000816 \n",
      "train_iterations:132 :0.000757 \n",
      "train_iterations:133 :0.000701 \n",
      "train_iterations:134 :0.000650 \n",
      "train_iterations:135 :0.000602 \n",
      "train_iterations:136 :0.000557 \n",
      "train_iterations:137 :0.000515 \n",
      "epoch7:train_loss,3.173596 val_loss:3.994835 lamb: 3.502493\n",
      "train_iterations:0 :inf \n",
      "train_iterations:1 :1113.914449 \n",
      "train_iterations:2 :150.406784 \n",
      "train_iterations:3 :28.611028 \n",
      "train_iterations:4 :11.105717 \n",
      "train_iterations:5 :7.090520 \n",
      "train_iterations:6 :5.785974 \n",
      "train_iterations:7 :5.131882 \n",
      "train_iterations:8 :4.942126 \n",
      "train_iterations:9 :4.910655 \n",
      "train_iterations:10 :4.901535 \n",
      "train_iterations:11 :4.889137 \n",
      "train_iterations:12 :4.855432 \n",
      "train_iterations:13 :4.793954 \n",
      "train_iterations:14 :4.702799 \n",
      "train_iterations:15 :4.585496 \n",
      "train_iterations:16 :4.453719 \n",
      "train_iterations:17 :4.295732 \n",
      "train_iterations:18 :4.115117 \n",
      "train_iterations:19 :3.928910 \n",
      "train_iterations:20 :3.741995 \n",
      "train_iterations:21 :3.560374 \n",
      "train_iterations:22 :3.382598 \n",
      "train_iterations:23 :3.201208 \n",
      "train_iterations:24 :3.031221 \n",
      "train_iterations:25 :2.864408 \n",
      "train_iterations:26 :2.700964 \n",
      "train_iterations:27 :2.540988 \n",
      "train_iterations:28 :2.385379 \n",
      "train_iterations:29 :2.235083 \n",
      "train_iterations:30 :2.092123 \n",
      "train_iterations:31 :1.956330 \n",
      "train_iterations:32 :1.828068 \n",
      "train_iterations:33 :1.707761 \n",
      "train_iterations:34 :1.595811 \n",
      "train_iterations:35 :1.493438 \n",
      "train_iterations:36 :1.403188 \n",
      "train_iterations:37 :1.319843 \n",
      "train_iterations:38 :1.241068 \n",
      "train_iterations:39 :1.169787 \n",
      "train_iterations:40 :1.103917 \n",
      "train_iterations:41 :1.042763 \n",
      "train_iterations:42 :0.982814 \n",
      "train_iterations:43 :0.928354 \n",
      "train_iterations:44 :0.877868 \n",
      "train_iterations:45 :0.829408 \n",
      "train_iterations:46 :0.782521 \n",
      "train_iterations:47 :0.738099 \n",
      "train_iterations:48 :0.695420 \n",
      "train_iterations:49 :0.654147 \n",
      "train_iterations:50 :0.614681 \n",
      "train_iterations:51 :0.576678 \n",
      "train_iterations:52 :0.540265 \n",
      "train_iterations:53 :0.505381 \n",
      "train_iterations:54 :0.472439 \n",
      "train_iterations:55 :0.441768 \n",
      "train_iterations:56 :0.413639 \n",
      "train_iterations:57 :0.387767 \n",
      "train_iterations:58 :0.364016 \n",
      "train_iterations:59 :0.342251 \n",
      "train_iterations:60 :0.322309 \n",
      "train_iterations:61 :0.304014 \n",
      "train_iterations:62 :0.287179 \n",
      "train_iterations:63 :0.271617 \n",
      "train_iterations:64 :0.257100 \n",
      "train_iterations:65 :0.243584 \n",
      "train_iterations:66 :0.230876 \n",
      "train_iterations:67 :0.218868 \n",
      "train_iterations:68 :0.207535 \n",
      "train_iterations:69 :0.196766 \n",
      "train_iterations:70 :0.186533 \n",
      "train_iterations:71 :0.176783 \n",
      "train_iterations:72 :0.167484 \n",
      "train_iterations:73 :0.158620 \n",
      "train_iterations:74 :0.150189 \n",
      "train_iterations:75 :0.142159 \n",
      "train_iterations:76 :0.134511 \n",
      "train_iterations:77 :0.127232 \n",
      "train_iterations:78 :0.120299 \n",
      "train_iterations:79 :0.113718 \n",
      "train_iterations:80 :0.107459 \n",
      "train_iterations:81 :0.101504 \n",
      "train_iterations:82 :0.095880 \n",
      "train_iterations:83 :0.090566 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_iterations:84 :0.085542 \n",
      "train_iterations:85 :0.080790 \n",
      "train_iterations:86 :0.076297 \n",
      "train_iterations:87 :0.072059 \n",
      "train_iterations:88 :0.068061 \n",
      "train_iterations:89 :0.064282 \n",
      "train_iterations:90 :0.060704 \n",
      "train_iterations:91 :0.057333 \n",
      "train_iterations:92 :0.054164 \n",
      "train_iterations:93 :0.051182 \n",
      "train_iterations:94 :0.048380 \n",
      "train_iterations:95 :0.045750 \n",
      "train_iterations:96 :0.043279 \n",
      "train_iterations:97 :0.040957 \n",
      "train_iterations:98 :0.038772 \n",
      "train_iterations:99 :0.036711 \n",
      "train_iterations:100 :0.034767 \n",
      "train_iterations:101 :0.032929 \n",
      "train_iterations:102 :0.031190 \n",
      "train_iterations:103 :0.029543 \n",
      "train_iterations:104 :0.027982 \n",
      "train_iterations:105 :0.026501 \n",
      "train_iterations:106 :0.025096 \n",
      "train_iterations:107 :0.023761 \n",
      "train_iterations:108 :0.022493 \n",
      "train_iterations:109 :0.021288 \n",
      "train_iterations:110 :0.020138 \n",
      "train_iterations:111 :0.019040 \n",
      "train_iterations:112 :0.018002 \n",
      "train_iterations:113 :0.017024 \n",
      "train_iterations:114 :0.016101 \n",
      "train_iterations:115 :0.015231 \n",
      "train_iterations:116 :0.014409 \n",
      "train_iterations:117 :0.013631 \n",
      "train_iterations:118 :0.012894 \n",
      "train_iterations:119 :0.012197 \n",
      "train_iterations:120 :0.011536 \n",
      "train_iterations:121 :0.010911 \n",
      "train_iterations:122 :0.010320 \n",
      "train_iterations:123 :0.009762 \n",
      "train_iterations:124 :0.009236 \n",
      "train_iterations:125 :0.008740 \n",
      "train_iterations:126 :0.008272 \n",
      "train_iterations:127 :0.007832 \n",
      "train_iterations:128 :0.007417 \n",
      "train_iterations:129 :0.007026 \n",
      "train_iterations:130 :0.006657 \n",
      "train_iterations:131 :0.006309 \n",
      "train_iterations:132 :0.005981 \n",
      "train_iterations:133 :0.005670 \n",
      "train_iterations:134 :0.005377 \n",
      "train_iterations:135 :0.005099 \n",
      "train_iterations:136 :0.004835 \n",
      "train_iterations:137 :0.004586 \n",
      "train_iterations:138 :0.004349 \n",
      "train_iterations:139 :0.004124 \n",
      "train_iterations:140 :0.003911 \n",
      "train_iterations:141 :0.003709 \n",
      "train_iterations:142 :0.003517 \n",
      "train_iterations:143 :0.003335 \n",
      "train_iterations:144 :0.003162 \n",
      "train_iterations:145 :0.002998 \n",
      "train_iterations:146 :0.002842 \n",
      "train_iterations:147 :0.002695 \n",
      "train_iterations:148 :0.002554 \n",
      "train_iterations:149 :0.002421 \n",
      "train_iterations:150 :0.002295 \n",
      "train_iterations:151 :0.002175 \n",
      "train_iterations:152 :0.002062 \n",
      "train_iterations:153 :0.001954 \n",
      "train_iterations:154 :0.001852 \n",
      "train_iterations:155 :0.001756 \n",
      "train_iterations:156 :0.001664 \n",
      "train_iterations:157 :0.001577 \n",
      "train_iterations:158 :0.001495 \n",
      "train_iterations:159 :0.001417 \n",
      "train_iterations:160 :0.001343 \n",
      "train_iterations:161 :0.001273 \n",
      "train_iterations:162 :0.001207 \n",
      "train_iterations:163 :0.001144 \n",
      "train_iterations:164 :0.001085 \n",
      "train_iterations:165 :0.001028 \n",
      "train_iterations:166 :0.000975 \n",
      "train_iterations:167 :0.000924 \n",
      "train_iterations:168 :0.000876 \n",
      "train_iterations:169 :0.000831 \n",
      "train_iterations:170 :0.000788 \n",
      "train_iterations:171 :0.000747 \n",
      "train_iterations:172 :0.000708 \n",
      "train_iterations:173 :0.000671 \n",
      "train_iterations:174 :0.000636 \n",
      "train_iterations:175 :0.000603 \n",
      "train_iterations:176 :0.000572 \n",
      "train_iterations:177 :0.000542 \n",
      "train_iterations:178 :0.000514 \n",
      "epoch8:train_loss,2.678387 val_loss:3.801961 lamb: 1.751246\n",
      "train_iterations:0 :inf \n",
      "train_iterations:1 :713.249634 \n",
      "train_iterations:2 :117.474321 \n",
      "train_iterations:3 :27.116925 \n",
      "train_iterations:4 :10.484372 \n",
      "train_iterations:5 :5.425595 \n",
      "train_iterations:6 :3.493749 \n",
      "train_iterations:7 :2.582411 \n",
      "train_iterations:8 :2.278568 \n",
      "train_iterations:9 :2.202029 \n",
      "train_iterations:10 :2.213227 \n",
      "train_iterations:11 :2.255026 \n",
      "train_iterations:12 :2.302360 \n",
      "train_iterations:13 :2.342859 \n",
      "train_iterations:14 :2.370996 \n",
      "train_iterations:15 :2.384653 \n",
      "train_iterations:16 :2.383586 \n",
      "train_iterations:17 :2.368493 \n",
      "train_iterations:18 :2.340176 \n",
      "train_iterations:19 :2.300596 \n",
      "train_iterations:20 :2.253188 \n",
      "train_iterations:21 :2.198727 \n",
      "train_iterations:22 :2.138419 \n",
      "train_iterations:23 :2.076828 \n",
      "train_iterations:24 :2.010969 \n",
      "train_iterations:25 :1.942315 \n",
      "train_iterations:26 :1.872773 \n",
      "train_iterations:27 :1.804881 \n",
      "train_iterations:28 :1.737959 \n",
      "train_iterations:29 :1.671706 \n",
      "train_iterations:30 :1.604891 \n",
      "train_iterations:31 :1.539657 \n",
      "train_iterations:32 :1.475653 \n",
      "train_iterations:33 :1.413174 \n",
      "train_iterations:34 :1.352475 \n",
      "train_iterations:35 :1.293724 \n",
      "train_iterations:36 :1.236896 \n",
      "train_iterations:37 :1.182191 \n",
      "train_iterations:38 :1.129630 \n",
      "train_iterations:39 :1.078775 \n",
      "train_iterations:40 :1.029999 \n",
      "train_iterations:41 :0.983405 \n",
      "train_iterations:42 :0.938944 \n",
      "train_iterations:43 :0.896570 \n",
      "train_iterations:44 :0.856270 \n",
      "train_iterations:45 :0.817995 \n",
      "train_iterations:46 :0.781403 \n",
      "train_iterations:47 :0.746494 \n",
      "train_iterations:48 :0.713266 \n",
      "train_iterations:49 :0.681724 \n",
      "train_iterations:50 :0.651774 \n",
      "train_iterations:51 :0.623290 \n",
      "train_iterations:52 :0.596116 \n",
      "train_iterations:53 :0.570321 \n",
      "train_iterations:54 :0.544474 \n",
      "train_iterations:55 :0.520094 \n",
      "train_iterations:56 :0.496976 \n",
      "train_iterations:57 :0.474808 \n",
      "train_iterations:58 :0.453385 \n",
      "train_iterations:59 :0.432703 \n",
      "train_iterations:60 :0.412811 \n",
      "train_iterations:61 :0.393741 \n",
      "train_iterations:62 :0.375517 \n",
      "train_iterations:63 :0.358133 \n",
      "train_iterations:64 :0.341596 \n",
      "train_iterations:65 :0.325883 \n",
      "train_iterations:66 :0.310936 \n",
      "train_iterations:67 :0.296732 \n",
      "train_iterations:68 :0.283195 \n",
      "train_iterations:69 :0.270379 \n",
      "train_iterations:70 :0.258201 \n",
      "train_iterations:71 :0.246629 \n",
      "train_iterations:72 :0.235652 \n",
      "train_iterations:73 :0.225162 \n",
      "train_iterations:74 :0.215179 \n",
      "train_iterations:75 :0.205676 \n",
      "train_iterations:76 :0.196620 \n",
      "train_iterations:77 :0.187991 \n",
      "train_iterations:78 :0.179769 \n",
      "train_iterations:79 :0.171933 \n",
      "train_iterations:80 :0.164462 \n",
      "train_iterations:81 :0.157333 \n",
      "train_iterations:82 :0.150528 \n",
      "train_iterations:83 :0.144034 \n",
      "train_iterations:84 :0.137816 \n",
      "train_iterations:85 :0.131865 \n",
      "train_iterations:86 :0.126178 \n",
      "train_iterations:87 :0.120740 \n",
      "train_iterations:88 :0.115536 \n",
      "train_iterations:89 :0.110554 \n",
      "train_iterations:90 :0.105783 \n",
      "train_iterations:91 :0.101216 \n",
      "train_iterations:92 :0.096822 \n",
      "train_iterations:93 :0.092611 \n",
      "train_iterations:94 :0.088583 \n",
      "train_iterations:95 :0.084727 \n",
      "train_iterations:96 :0.081039 \n",
      "train_iterations:97 :0.077509 \n",
      "train_iterations:98 :0.074133 \n",
      "train_iterations:99 :0.070903 \n",
      "train_iterations:100 :0.067814 \n",
      "train_iterations:101 :0.064871 \n",
      "train_iterations:102 :0.062052 \n",
      "train_iterations:103 :0.059355 \n",
      "train_iterations:104 :0.056773 \n",
      "train_iterations:105 :0.054301 \n",
      "train_iterations:106 :0.051937 \n",
      "train_iterations:107 :0.049675 \n",
      "train_iterations:108 :0.047512 \n",
      "train_iterations:109 :0.045442 \n",
      "train_iterations:110 :0.043464 \n",
      "train_iterations:111 :0.041571 \n",
      "train_iterations:112 :0.039762 \n",
      "train_iterations:113 :0.038032 \n",
      "train_iterations:114 :0.036377 \n",
      "train_iterations:115 :0.034793 \n",
      "train_iterations:116 :0.033279 \n",
      "train_iterations:117 :0.031832 \n",
      "train_iterations:118 :0.030443 \n",
      "train_iterations:119 :0.029119 \n",
      "train_iterations:120 :0.027855 \n",
      "train_iterations:121 :0.026646 \n",
      "train_iterations:122 :0.025487 \n",
      "train_iterations:123 :0.024378 \n",
      "train_iterations:124 :0.023316 \n",
      "train_iterations:125 :0.022300 \n",
      "train_iterations:126 :0.021329 \n",
      "train_iterations:127 :0.020400 \n",
      "train_iterations:128 :0.019513 \n",
      "train_iterations:129 :0.018667 \n",
      "train_iterations:130 :0.017858 \n",
      "train_iterations:131 :0.017087 \n",
      "train_iterations:132 :0.016350 \n",
      "train_iterations:133 :0.015646 \n",
      "train_iterations:134 :0.014974 \n",
      "train_iterations:135 :0.014331 \n",
      "train_iterations:136 :0.013717 \n",
      "train_iterations:137 :0.013130 \n",
      "train_iterations:138 :0.012569 \n",
      "train_iterations:139 :0.012032 \n",
      "train_iterations:140 :0.011519 \n",
      "train_iterations:141 :0.011028 \n",
      "train_iterations:142 :0.010558 \n",
      "train_iterations:143 :0.010108 \n",
      "train_iterations:144 :0.009677 \n",
      "train_iterations:145 :0.009265 \n",
      "train_iterations:146 :0.008870 \n",
      "train_iterations:147 :0.008492 \n",
      "train_iterations:148 :0.008130 \n",
      "train_iterations:149 :0.007784 \n",
      "train_iterations:150 :0.007453 \n",
      "train_iterations:151 :0.007135 \n",
      "train_iterations:152 :0.006832 \n",
      "train_iterations:153 :0.006541 \n",
      "train_iterations:154 :0.006262 \n",
      "train_iterations:155 :0.005996 \n",
      "train_iterations:156 :0.005740 \n",
      "train_iterations:157 :0.005495 \n",
      "train_iterations:158 :0.005261 \n",
      "train_iterations:159 :0.005037 \n",
      "train_iterations:160 :0.004822 \n",
      "train_iterations:161 :0.004616 \n",
      "train_iterations:162 :0.004419 \n",
      "train_iterations:163 :0.004231 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_iterations:164 :0.004050 \n",
      "train_iterations:165 :0.003877 \n",
      "train_iterations:166 :0.003712 \n",
      "train_iterations:167 :0.003553 \n",
      "train_iterations:168 :0.003401 \n",
      "train_iterations:169 :0.003256 \n",
      "train_iterations:170 :0.003117 \n",
      "train_iterations:171 :0.002984 \n",
      "train_iterations:172 :0.002856 \n",
      "train_iterations:173 :0.002734 \n",
      "train_iterations:174 :0.002618 \n",
      "train_iterations:175 :0.002506 \n",
      "train_iterations:176 :0.002399 \n",
      "train_iterations:177 :0.002296 \n",
      "train_iterations:178 :0.002198 \n",
      "train_iterations:179 :0.002104 \n",
      "train_iterations:180 :0.002014 \n",
      "train_iterations:181 :0.001928 \n",
      "train_iterations:182 :0.001846 \n",
      "train_iterations:183 :0.001767 \n",
      "train_iterations:184 :0.001691 \n",
      "train_iterations:185 :0.001619 \n",
      "train_iterations:186 :0.001550 \n",
      "train_iterations:187 :0.001484 \n",
      "train_iterations:188 :0.001420 \n",
      "train_iterations:189 :0.001360 \n",
      "train_iterations:190 :0.001302 \n",
      "train_iterations:191 :0.001246 \n",
      "train_iterations:192 :0.001193 \n",
      "train_iterations:193 :0.001142 \n",
      "train_iterations:194 :0.001093 \n",
      "train_iterations:195 :0.001046 \n",
      "train_iterations:196 :0.001002 \n",
      "train_iterations:197 :0.000959 \n",
      "train_iterations:198 :0.000918 \n",
      "train_iterations:199 :0.000879 \n",
      "train_iterations:200 :0.000841 \n",
      "train_iterations:201 :0.000805 \n",
      "train_iterations:202 :0.000771 \n",
      "train_iterations:203 :0.000738 \n",
      "train_iterations:204 :0.000706 \n",
      "train_iterations:205 :0.000676 \n",
      "train_iterations:206 :0.000647 \n",
      "train_iterations:207 :0.000620 \n",
      "train_iterations:208 :0.000593 \n",
      "train_iterations:209 :0.000568 \n",
      "train_iterations:210 :0.000544 \n",
      "train_iterations:211 :0.000521 \n",
      "epoch9:train_loss,2.362924 val_loss:3.833979 lamb: 0.875623\n"
     ]
    }
   ],
   "source": [
    "while delta_val_loss >=0:\n",
    "    if epoch==0:\n",
    "        l_wine.fit(train_data,train_labels,lamb,init=True)\n",
    "    else:\n",
    "        l_wine.fit(train_data,train_labels,lamb,init=False)\n",
    "    train_pred = l_wine.predict(train_data)\n",
    "    val_pred = l_wine.predict(val_data)\n",
    "    \n",
    "    train_loss = RMSE(train_pred,train_labels)\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    val_loss_pre = val_loss\n",
    "    val_loss = RMSE(val_pred,val_labels)\n",
    "    val_loss_list.append(val_loss)\n",
    "    delta_val_loss = val_loss_pre - val_loss\n",
    "    lamb = lamb/2\n",
    "    epoch = epoch + 1\n",
    "    \n",
    "    wt,b = l_wine.get_param()\n",
    "    nonzero = np.count_nonzero(wt)\n",
    "    nonzero_list.append(nonzero)\n",
    "    print(\"epoch %d:train_loss,%f val_loss:%f lamb: %f\"%(epoch,train_loss,val_loss,lamb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot the RMSE-lamdba curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lamb = max_lamb(train_data,train_labels)\n",
    "lamb_list = [lamb]\n",
    "for i in range(len(train_loss_list)-1):\n",
    "    lamb = lamb/2\n",
    "    lamb_list.append(lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d949763828>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKRf3/wEr7twXECfODQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d9496d5828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure(1)\n",
    "plt.title('RMSE-Lambda')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "plt.plot(lamb_list,train_loss_list,label='train_loss')\n",
    "plt.plot(lamb_list,val_loss_list,label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d9497daeb8>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEWCAYAAACe8xtsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nK5uTh5mZlc3Jw8zMyubkYWZmZfv/sfpcfM+4pTwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d94976ef28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2)\n",
    "plt.title(\"nonzero_number - lambda\")\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('nonzero_number')\n",
    "plt.plot(lamb_list,nonzero_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open(\"./model/param_43.txt\",\"wb\") as file:\n",
    "    pickle.dump([wt,b],file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the top 10 and last 10 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt,b = l_wine.get_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt = np.array(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = np.argsort(wt[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data/featureTypes.txt')\n",
    "features = file.readlines()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "for feature in features:\n",
    "    feature_list.append(feature[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apricots\n",
      "\n",
      "acidity provides\n",
      "\n",
      "truly\n",
      "\n",
      "nearly\n",
      "\n",
      "lemony\n",
      "\n",
      "ageability\n",
      "\n",
      "stars\n",
      "\n",
      "big\n",
      "\n",
      "lifesaver\n",
      "\n",
      "spearmint\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in list[-10:]:\n",
    "    print(features[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "earns\n",
      "\n",
      "cherry berry\n",
      "\n",
      "liqueur\n",
      "\n",
      "semillon\n",
      "\n",
      "sparkler\n",
      "\n",
      "high\n",
      "\n",
      "soft\n",
      "\n",
      "banana\n",
      "\n",
      "cuts\n",
      "\n",
      "rest\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for feature in list[0:10]:\n",
    "    print(features[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_data\n",
    "del train_labels\n",
    "del val_data \n",
    "del val_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load test data\n",
    "# num of test data\n",
    "num_test = 20534\n",
    "test_data = np.loadtxt('./data/testData.txt')\n",
    "test_data = coo_matrix((test_data[:,2],(test_data[:,1]-1,test_data[:,0]-1)),shape=(d,num_test)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(l_wine.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/sampleSubmission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Points'] = pred.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission_load_weight.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[ 1.11912636,  4.61712258,  6.59211588, ..., -0.16141947,\n",
       "           1.09418857,  2.9329912 ]]), 80.88960920020232)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_wine.load_model(\"./model/param.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = l_wine.predict(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = RMSE(val_pred,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.445766408989055\n"
     ]
    }
   ],
   "source": [
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[0.        , 3.36333644, 4.60033338, ..., 0.        , 0.73763161,\n",
       "          1.44124522]]), 82.40787983857409)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_wine.load_model(\"./model/param_43.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = l_wine.predict(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = RMSE(val_pred,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8339786667294247\n"
     ]
    }
   ],
   "source": [
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_data.todense())\n",
    "val_data = np.array(val_data.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((train_data,val_data),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 20000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = csr_matrix(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate((train_labels,val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_iterations:0 :inf \n",
      "train_iterations:1 :157139007.548303 \n",
      "train_iterations:2 :31918.594313 \n",
      "train_iterations:3 :4777.559720 \n",
      "train_iterations:4 :1396.862237 \n",
      "train_iterations:5 :603.133777 \n",
      "train_iterations:6 :332.808805 \n",
      "train_iterations:7 :221.751496 \n",
      "train_iterations:8 :180.036501 \n",
      "train_iterations:9 :164.386678 \n",
      "train_iterations:10 :159.142561 \n",
      "train_iterations:11 :159.065611 \n",
      "train_iterations:12 :161.859258 \n",
      "train_iterations:13 :165.647136 \n",
      "train_iterations:14 :170.958035 \n",
      "train_iterations:15 :177.191072 \n",
      "train_iterations:16 :183.612555 \n",
      "train_iterations:17 :190.466155 \n",
      "train_iterations:18 :196.975441 \n",
      "train_iterations:19 :203.739839 \n",
      "train_iterations:20 :210.339044 \n",
      "train_iterations:21 :216.089145 \n",
      "train_iterations:22 :221.153564 \n",
      "train_iterations:23 :225.209402 \n",
      "train_iterations:24 :227.560807 \n",
      "train_iterations:25 :228.604856 \n",
      "train_iterations:26 :228.004111 \n",
      "train_iterations:27 :225.882304 \n",
      "train_iterations:28 :222.123363 \n",
      "train_iterations:29 :217.978650 \n",
      "train_iterations:30 :211.786220 \n",
      "train_iterations:31 :204.886560 \n",
      "train_iterations:32 :197.174304 \n",
      "train_iterations:33 :188.900178 \n",
      "train_iterations:34 :179.931886 \n",
      "train_iterations:35 :171.173396 \n",
      "train_iterations:36 :162.684468 \n",
      "train_iterations:37 :154.386357 \n",
      "train_iterations:38 :146.314923 \n",
      "train_iterations:39 :137.677791 \n",
      "train_iterations:40 :129.997251 \n",
      "train_iterations:41 :122.772639 \n",
      "train_iterations:42 :116.228826 \n",
      "train_iterations:43 :110.178079 \n",
      "train_iterations:44 :104.473204 \n",
      "train_iterations:45 :99.108282 \n",
      "train_iterations:46 :94.050917 \n",
      "train_iterations:47 :89.391578 \n",
      "train_iterations:48 :85.001394 \n",
      "train_iterations:49 :80.815428 \n",
      "train_iterations:50 :77.090437 \n",
      "train_iterations:51 :73.380987 \n",
      "train_iterations:52 :69.913949 \n",
      "train_iterations:53 :66.727025 \n",
      "train_iterations:54 :63.816480 \n",
      "train_iterations:55 :61.053616 \n",
      "train_iterations:56 :58.350097 \n",
      "train_iterations:57 :55.845505 \n",
      "train_iterations:58 :53.477129 \n",
      "train_iterations:59 :51.281526 \n",
      "train_iterations:60 :49.175428 \n",
      "train_iterations:61 :47.119249 \n",
      "train_iterations:62 :45.136263 \n",
      "train_iterations:63 :43.222425 \n",
      "train_iterations:64 :41.354303 \n",
      "train_iterations:65 :39.518572 \n",
      "train_iterations:66 :37.652808 \n",
      "train_iterations:67 :35.965778 \n",
      "train_iterations:68 :34.340526 \n",
      "train_iterations:69 :32.687682 \n",
      "train_iterations:70 :31.196833 \n",
      "train_iterations:71 :29.763296 \n",
      "train_iterations:72 :28.381647 \n",
      "train_iterations:73 :27.055633 \n",
      "train_iterations:74 :25.840740 \n",
      "train_iterations:75 :24.752007 \n",
      "train_iterations:76 :23.670076 \n",
      "train_iterations:77 :22.575462 \n",
      "train_iterations:78 :21.475288 \n",
      "train_iterations:79 :20.445395 \n",
      "train_iterations:80 :19.479024 \n",
      "train_iterations:81 :18.584080 \n",
      "train_iterations:82 :17.689945 \n",
      "train_iterations:83 :16.862895 \n",
      "train_iterations:84 :16.089612 \n",
      "train_iterations:85 :15.364913 \n",
      "train_iterations:86 :14.680639 \n",
      "train_iterations:87 :14.036998 \n",
      "train_iterations:88 :13.428465 \n",
      "train_iterations:89 :12.858059 \n",
      "train_iterations:90 :12.315997 \n",
      "train_iterations:91 :11.796743 \n",
      "train_iterations:92 :11.296785 \n",
      "train_iterations:93 :10.815610 \n",
      "train_iterations:94 :10.344379 \n",
      "train_iterations:95 :9.892860 \n",
      "train_iterations:96 :9.461138 \n",
      "train_iterations:97 :9.050734 \n",
      "train_iterations:98 :8.647676 \n",
      "train_iterations:99 :8.235308 \n",
      "train_iterations:100 :7.853741 \n",
      "train_iterations:101 :7.490037 \n",
      "train_iterations:102 :7.138666 \n",
      "train_iterations:103 :6.800435 \n",
      "train_iterations:104 :6.474714 \n",
      "train_iterations:105 :6.160449 \n",
      "train_iterations:106 :5.862470 \n",
      "train_iterations:107 :5.579106 \n",
      "train_iterations:108 :5.311557 \n",
      "train_iterations:109 :5.059270 \n",
      "train_iterations:110 :4.822672 \n",
      "train_iterations:111 :4.599776 \n",
      "train_iterations:112 :4.388149 \n",
      "train_iterations:113 :4.189830 \n",
      "train_iterations:114 :4.002628 \n",
      "train_iterations:115 :3.825341 \n",
      "train_iterations:116 :3.657424 \n",
      "train_iterations:117 :3.498257 \n",
      "train_iterations:118 :3.347909 \n",
      "train_iterations:119 :3.205106 \n",
      "train_iterations:120 :3.069580 \n",
      "train_iterations:121 :2.940913 \n",
      "train_iterations:122 :2.818808 \n",
      "train_iterations:123 :2.702747 \n",
      "train_iterations:124 :2.592193 \n",
      "train_iterations:125 :2.487126 \n",
      "train_iterations:126 :2.387326 \n",
      "train_iterations:127 :2.291847 \n",
      "train_iterations:128 :2.200212 \n",
      "train_iterations:129 :2.111906 \n",
      "train_iterations:130 :2.027469 \n",
      "train_iterations:131 :1.946379 \n",
      "train_iterations:132 :1.868244 \n",
      "train_iterations:133 :1.792822 \n",
      "train_iterations:134 :1.720123 \n",
      "train_iterations:135 :1.650398 \n",
      "train_iterations:136 :1.583262 \n",
      "train_iterations:137 :1.518521 \n",
      "train_iterations:138 :1.456351 \n",
      "train_iterations:139 :1.396701 \n",
      "train_iterations:140 :1.339316 \n",
      "train_iterations:141 :1.284050 \n",
      "train_iterations:142 :1.230884 \n",
      "train_iterations:143 :1.179788 \n",
      "train_iterations:144 :1.130782 \n",
      "train_iterations:145 :1.083757 \n",
      "train_iterations:146 :1.038536 \n",
      "train_iterations:147 :0.995119 \n",
      "train_iterations:148 :0.953451 \n",
      "train_iterations:149 :0.913472 \n",
      "train_iterations:150 :0.875116 \n",
      "train_iterations:151 :0.838331 \n",
      "train_iterations:152 :0.803037 \n",
      "train_iterations:153 :0.769177 \n",
      "train_iterations:154 :0.736780 \n",
      "train_iterations:155 :0.705688 \n",
      "train_iterations:156 :0.675888 \n",
      "train_iterations:157 :0.647234 \n",
      "train_iterations:158 :0.619387 \n",
      "train_iterations:159 :0.592860 \n",
      "train_iterations:160 :0.567634 \n",
      "train_iterations:161 :0.543582 \n",
      "train_iterations:162 :0.520525 \n",
      "train_iterations:163 :0.498419 \n",
      "train_iterations:164 :0.477220 \n",
      "train_iterations:165 :0.456888 \n",
      "train_iterations:166 :0.437417 \n",
      "train_iterations:167 :0.418720 \n",
      "train_iterations:168 :0.400773 \n",
      "train_iterations:169 :0.383555 \n",
      "train_iterations:170 :0.367030 \n",
      "train_iterations:171 :0.351175 \n",
      "train_iterations:172 :0.336011 \n",
      "train_iterations:173 :0.321463 \n",
      "train_iterations:174 :0.307517 \n",
      "train_iterations:175 :0.294146 \n",
      "train_iterations:176 :0.281333 \n",
      "train_iterations:177 :0.269065 \n",
      "train_iterations:178 :0.257325 \n",
      "train_iterations:179 :0.246112 \n",
      "train_iterations:180 :0.235404 \n",
      "train_iterations:181 :0.225174 \n",
      "train_iterations:182 :0.215404 \n",
      "train_iterations:183 :0.206069 \n",
      "train_iterations:184 :0.197163 \n",
      "train_iterations:185 :0.188663 \n",
      "train_iterations:186 :0.180549 \n",
      "train_iterations:187 :0.172788 \n",
      "train_iterations:188 :0.165354 \n",
      "train_iterations:189 :0.158260 \n",
      "train_iterations:190 :0.151490 \n",
      "train_iterations:191 :0.145027 \n",
      "train_iterations:192 :0.138852 \n",
      "train_iterations:193 :0.131095 \n",
      "train_iterations:194 :0.123683 \n",
      "train_iterations:195 :0.118065 \n",
      "train_iterations:196 :0.112797 \n",
      "train_iterations:197 :0.107802 \n",
      "train_iterations:198 :0.103040 \n",
      "train_iterations:199 :0.098501 \n",
      "train_iterations:200 :0.094176 \n",
      "train_iterations:201 :0.090060 \n",
      "train_iterations:202 :0.086137 \n",
      "train_iterations:203 :0.082416 \n",
      "train_iterations:204 :0.078873 \n",
      "train_iterations:205 :0.075496 \n",
      "train_iterations:206 :0.072275 \n",
      "train_iterations:207 :0.069215 \n",
      "train_iterations:208 :0.066191 \n",
      "train_iterations:209 :0.063373 \n",
      "train_iterations:210 :0.060672 \n",
      "train_iterations:211 :0.058083 \n",
      "train_iterations:212 :0.055600 \n",
      "train_iterations:213 :0.053220 \n",
      "train_iterations:214 :0.050939 \n",
      "train_iterations:215 :0.048753 \n",
      "train_iterations:216 :0.046658 \n",
      "train_iterations:217 :0.044635 \n",
      "train_iterations:218 :0.042708 \n",
      "train_iterations:219 :0.040868 \n",
      "train_iterations:220 :0.039107 \n",
      "train_iterations:221 :0.037419 \n",
      "train_iterations:222 :0.035803 \n",
      "train_iterations:223 :0.034256 \n",
      "train_iterations:224 :0.032774 \n",
      "train_iterations:225 :0.031357 \n",
      "train_iterations:226 :0.030000 \n",
      "train_iterations:227 :0.028702 \n",
      "train_iterations:228 :0.027460 \n",
      "train_iterations:229 :0.026272 \n",
      "train_iterations:230 :0.025135 \n",
      "train_iterations:231 :0.024048 \n",
      "train_iterations:232 :0.023007 \n",
      "train_iterations:233 :0.022013 \n",
      "train_iterations:234 :0.021061 \n",
      "train_iterations:235 :0.020151 \n",
      "train_iterations:236 :0.019280 \n",
      "train_iterations:237 :0.018447 \n",
      "train_iterations:238 :0.017650 \n",
      "train_iterations:239 :0.016888 \n",
      "train_iterations:240 :0.016159 \n",
      "train_iterations:241 :0.015462 \n",
      "train_iterations:242 :0.014795 \n",
      "train_iterations:243 :0.014157 \n",
      "train_iterations:244 :0.013546 \n",
      "train_iterations:245 :0.012962 \n",
      "train_iterations:246 :0.012403 \n",
      "train_iterations:247 :0.011868 \n",
      "train_iterations:248 :0.011356 \n",
      "train_iterations:249 :0.010866 \n",
      "train_iterations:250 :0.010398 \n",
      "train_iterations:251 :0.009949 \n",
      "train_iterations:252 :0.009520 \n",
      "train_iterations:253 :0.009110 \n",
      "train_iterations:254 :0.008717 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_iterations:255 :0.008341 \n",
      "train_iterations:256 :0.007981 \n",
      "train_iterations:257 :0.007637 \n",
      "train_iterations:258 :0.007307 \n",
      "train_iterations:259 :0.006992 \n",
      "train_iterations:260 :0.006690 \n",
      "train_iterations:261 :0.006401 \n",
      "train_iterations:262 :0.006125 \n",
      "train_iterations:263 :0.005861 \n",
      "train_iterations:264 :0.005608 \n",
      "train_iterations:265 :0.005366 \n",
      "train_iterations:266 :0.005134 \n",
      "train_iterations:267 :0.004913 \n",
      "train_iterations:268 :0.004701 \n",
      "train_iterations:269 :0.004498 \n",
      "train_iterations:270 :0.004304 \n",
      "train_iterations:271 :0.004118 \n",
      "train_iterations:272 :0.003941 \n",
      "train_iterations:273 :0.003771 \n",
      "train_iterations:274 :0.003609 \n",
      "train_iterations:275 :0.003454 \n",
      "train_iterations:276 :0.003305 \n",
      "train_iterations:277 :0.003163 \n",
      "train_iterations:278 :0.003027 \n",
      "train_iterations:279 :0.002896 \n",
      "train_iterations:280 :0.002772 \n",
      "train_iterations:281 :0.002652 \n",
      "train_iterations:282 :0.002538 \n",
      "train_iterations:283 :0.002429 \n",
      "train_iterations:284 :0.002324 \n",
      "train_iterations:285 :0.002224 \n",
      "train_iterations:286 :0.002128 \n",
      "train_iterations:287 :0.002036 \n",
      "train_iterations:288 :0.001948 \n",
      "train_iterations:289 :0.001864 \n",
      "train_iterations:290 :0.001784 \n",
      "train_iterations:291 :0.001707 \n",
      "train_iterations:292 :0.001633 \n",
      "train_iterations:293 :0.001563 \n",
      "train_iterations:294 :0.001496 \n",
      "train_iterations:295 :0.001431 \n",
      "train_iterations:296 :0.001369 \n",
      "train_iterations:297 :0.001310 \n",
      "train_iterations:298 :0.001254 \n",
      "train_iterations:299 :0.001199 \n",
      "train_iterations:300 :0.001148 \n",
      "train_iterations:301 :0.001098 \n",
      "train_iterations:302 :0.001051 \n",
      "train_iterations:303 :0.001005 \n",
      "train_iterations:304 :0.000962 \n",
      "train_iterations:305 :0.000921 \n",
      "train_iterations:306 :0.000881 \n",
      "train_iterations:307 :0.000843 \n",
      "train_iterations:308 :0.000807 \n",
      "train_iterations:309 :0.000772 \n",
      "train_iterations:310 :0.000738 \n",
      "train_iterations:311 :0.000707 \n",
      "train_iterations:312 :0.000676 \n",
      "train_iterations:313 :0.000647 \n",
      "train_iterations:314 :0.000619 \n",
      "train_iterations:315 :0.000592 \n",
      "train_iterations:316 :0.000567 \n",
      "train_iterations:317 :0.000542 \n",
      "train_iterations:318 :0.000519 \n"
     ]
    }
   ],
   "source": [
    "l_wine.fit(data,labels,lamb=1.751)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_wine.save_model(\"./model/param_alldata.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = l_wine.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse = RMSE(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_val_loss = 100\n",
    "loss = np.inf\n",
    "loss_list = []\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while delta_loss >=0:\n",
    "    if epoch==0:\n",
    "        l_wine.fit(data,labels,lamb,init=True)\n",
    "    else:\n",
    "        l_wine.fit(data,labels,lamb,init=False)\n",
    "    pred = l_wine.predict(data)\n",
    "    loss_pre = loss\n",
    "    loss = RMSE(pred,labels)\n",
    "    train_loss_list.append(loss)    \n",
    "    delta_loss = loss_pre - loss\n",
    "    lamb = lamb/2\n",
    "    epoch = epoch + 1\n",
    "    print(\"epoch %d:train_loss,%f lamb: %f\"%(epoch,loss,lamb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4431d7d2a5a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdel\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "del train_data\n",
    "del val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model\n",
    "# lamb = max_lamb(data,labels)\n",
    "lamb = 1.751\n",
    "l_2 = lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(matrix([[0.01519002, 4.340535  , 3.44175536, ..., 0.        , 0.02806004,\n",
       "          1.5089756 ]]), 81.69549086446727)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_2.load_model(\"./model/param_alldata.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_iterations:0 :inf \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\environment\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:742: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_iterations:1 :0.000475 \n",
      "train_iterations:2 :0.000455 \n",
      "train_iterations:3 :0.000435 \n",
      "train_iterations:4 :0.000416 \n",
      "train_iterations:5 :0.000398 \n",
      "train_iterations:6 :0.000381 \n",
      "train_iterations:7 :0.000365 \n",
      "train_iterations:8 :0.000349 \n",
      "train_iterations:9 :0.000334 \n",
      "train_iterations:10 :0.000320 \n",
      "train_iterations:11 :0.000306 \n",
      "train_iterations:12 :0.000293 \n",
      "train_iterations:13 :0.000280 \n",
      "train_iterations:14 :0.000268 \n",
      "train_iterations:15 :0.000256 \n",
      "train_iterations:16 :0.000245 \n",
      "train_iterations:17 :0.000235 \n",
      "train_iterations:18 :0.000225 \n",
      "train_iterations:19 :0.000215 \n",
      "train_iterations:20 :0.000206 \n",
      "train_iterations:21 :0.000197 \n",
      "train_iterations:22 :0.000188 \n",
      "train_iterations:23 :0.000180 \n",
      "train_iterations:24 :0.000172 \n",
      "train_iterations:25 :0.000165 \n",
      "train_iterations:26 :0.000158 \n",
      "train_iterations:27 :0.000151 \n",
      "train_iterations:28 :0.000145 \n",
      "train_iterations:29 :0.000138 \n",
      "train_iterations:30 :0.000132 \n",
      "train_iterations:31 :0.000127 \n",
      "train_iterations:32 :0.000121 \n",
      "train_iterations:33 :0.000116 \n",
      "train_iterations:34 :0.000111 \n",
      "train_iterations:35 :0.000106 \n",
      "train_iterations:36 :0.000102 \n",
      "train_iterations:37 :0.000097 \n",
      "train_iterations:38 :0.000093 \n",
      "train_iterations:39 :0.000089 \n",
      "train_iterations:40 :0.000085 \n",
      "train_iterations:41 :0.000081 \n",
      "train_iterations:42 :0.000078 \n",
      "train_iterations:43 :0.000075 \n",
      "train_iterations:44 :0.000071 \n",
      "train_iterations:45 :0.000068 \n",
      "train_iterations:46 :0.000065 \n",
      "train_iterations:47 :0.000063 \n",
      "train_iterations:48 :0.000060 \n",
      "train_iterations:49 :0.000057 \n",
      "train_iterations:50 :0.000055 \n",
      "train_iterations:51 :0.000052 \n",
      "train_iterations:52 :0.000050 \n",
      "train_iterations:53 :0.000048 \n",
      "train_iterations:54 :0.000046 \n",
      "train_iterations:55 :0.000044 \n",
      "train_iterations:56 :0.000042 \n",
      "train_iterations:57 :0.000040 \n",
      "train_iterations:58 :0.000039 \n",
      "train_iterations:59 :0.000037 \n",
      "train_iterations:60 :0.000035 \n",
      "train_iterations:61 :0.000034 \n",
      "train_iterations:62 :0.000032 \n",
      "train_iterations:63 :0.000031 \n",
      "train_iterations:64 :0.000030 \n",
      "train_iterations:65 :0.000028 \n",
      "train_iterations:66 :0.000027 \n",
      "train_iterations:67 :0.000026 \n",
      "train_iterations:68 :0.000025 \n",
      "train_iterations:69 :0.000024 \n",
      "train_iterations:70 :0.000023 \n",
      "train_iterations:71 :0.000022 \n",
      "train_iterations:72 :0.000021 \n",
      "train_iterations:73 :0.000020 \n",
      "train_iterations:74 :0.000019 \n",
      "train_iterations:75 :0.000018 \n",
      "train_iterations:76 :0.000017 \n",
      "train_iterations:77 :0.000017 \n",
      "train_iterations:78 :0.000016 \n",
      "train_iterations:79 :0.000015 \n",
      "train_iterations:80 :0.000015 \n",
      "train_iterations:81 :0.000014 \n",
      "train_iterations:82 :0.000013 \n",
      "train_iterations:83 :0.000013 \n",
      "train_iterations:84 :0.000012 \n",
      "train_iterations:85 :0.000012 \n",
      "train_iterations:86 :0.000011 \n",
      "train_iterations:87 :0.000011 \n",
      "train_iterations:88 :0.000010 \n"
     ]
    }
   ],
   "source": [
    "l_2.fit(data,labels,lamb,init=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
